{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (DataPipe.py, line 23)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/ecbm4040/anaconda3/envs/envTF22/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3331\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-e6b2984e0c3a>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from Data.DataPipe import DataGenerator\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/ecbm4040/CNNDetection-TF2.0/Data/DataPipe.py\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    'rz_interp':'bilinear',\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from Data.DataPipe import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense,Input,GlobalAveragePooling2D,AveragePooling2D\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "base_model = applications.ResNet50(weights='imagenet', include_top=False)  \n",
    "#base_model = applications.xception.Xception(weights='imagenet', include_top=False, input_shape=[resize_H,resize_W,channel]) \n",
    "\n",
    "for layer in base_model.layers[:140]:  # Keep the pretrained params\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[140:]:  # Keep the pretrained params\n",
    "    layer.trainable = True\n",
    "    \n",
    "x = base_model.output  # \n",
    "x = GlobalAveragePooling2D()(x)  \n",
    "# x = Dense(1024, activation='relu', name='fc1',kernel_regularizer=keras.regularizers.l2(0.0001))(x)  \n",
    "# x = Dropout(0.5)(x)  # Droupout 0.6\n",
    "# x = Dense(512, activation='relu', name='fc2',kernel_regularizer=keras.regularizers.l2(0.0001))(x)\n",
    "# #x = Dropout(0.5)(x)\n",
    "predictions = Dense(1, name='predictions')(x)  \n",
    "\n",
    "model = Model(base_model.input,predictions)\n",
    "optimizer = tf.optimizers.Adam(lr = 1e-4)\n",
    "loss=tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "model.compile(optimizer=optimizer,loss=loss,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = DataGenerator(file_index=a,root_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  51/2812 [..............................] - ETA: 1:41:58 - loss: 1.0336 - accuracy: 0.4478"
     ]
    }
   ],
   "source": [
    "model.fit(A,epochs=1,verbose=True,workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('image_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = [a.loc[k]['file'] for k in [0,1,2]]\n",
    "labels = [a.loc[k]['label'] for k in [0,1,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for path in img_path:\n",
    "    path =  '../e4040-proj-data/'+path\n",
    "    img = cv2.imread(path)   \n",
    "    imgs.append(img)\n",
    "imgs = np.array(imgs).astype(np.float32)\n",
    "imgs = imgs / 255.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
