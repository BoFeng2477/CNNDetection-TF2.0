## CNNDetection - TensorFlow 2.2 Version [[Original paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_CNN-Generated_Images_Are_Surprisingly_Easy_to_Spot..._for_Now_CVPR_2020_paper.html)



## (1) Environment Setup

### Create a conda virtual environment

-  `conda create -n CNNDET-TF python=3.7 `

### Install all required packages

- `pip install -r requirements.txt`

## (2) Dataset Preparation

### Training set

We used the same training set as in the original paper, it is provided [here](https://drive.google.com/file/d/1iVNBV0glknyTYGA9bCxT_d0CVTOgGcKh/view?usp=sharing) .

All images in the training set are from LSUN or generated by ProGAN, and they are pre-separated in 20 object categories. For every category, the so-named `0_real` sub-folder contains real-world images, while network-generated images are in the `1_fake` sub-folder.

### Validation set

Same to the original paper, where a certain amount of ProGAN generated real and fake images were taken out as validation set, we used the validation set to monitor our training process. The validation set can be downloaded [here](https://drive.google.com/file/d/1FU7xF8Wl_F8b0tgL0529qg2nZ_RpdVNL/view?usp=sharing). The directory structure follows the same rule as training set.

### Test set

All testsets used in our report can be downloaded [here](https://drive.google.com/file/d/1z_fD3UKgWQyOTZIBbYSaQ-hz4AzUrLC1/view?usp=sharing).

Our whole test set contains images generated from 13 image generative models, including images from 11 models that were tested in the original paper, as well as images from 2 extra sources([StyleGAN2](https://github.com/NVlabs/stylegan2), [whichfaceisreal](https://www.whichfaceisreal.com/)). Images of different generative models are stored in different directories, named after the exact model. Similar as above, real-world images are in `0_real` sub-folder and synthetic images are in `1_fake` sub-folder.

For sources that contains multiple classes like ProGAN, images from different classes are organized in separate subdirectories similar to training set.

## (3) Model training
To start a model training, please download at least the whole [training set](https://drive.google.com/file/d/1iVNBV0glknyTYGA9bCxT_d0CVTOgGcKh/view?usp=sharing), validation set is optional.

Here we provide 
```
python train_script.py [Arguments] 
```
Available Arguments:

```--train_dir``` Path to set directory (default to `../Copy_of_progan_train/train/`)

```--val_dir``` Path to validation set directory (default to `../progan_val/`)

```--train_index``` Path to training set index csv file (default to `Img_index/train/progan_train.csv`)

```--val_index``` Path to validation set index csv file (default to `Img_index/val/progan_val.csv`)

```--checkpoint``` Path to the checkpoint to restore model (default to ```None```)


## (4) Model Evaluation

### Download our pre-trained models:

| Model name    | Trained on       | Train-time Data Augmentation |
| :------------ | :--------------- | ---------------------------- |
| Model-2-class | 2-class Pro-GAN  | Blur: 0.5         JPEG: 0.5  |
| Model-8-class | 8-class Pro-GAN  | Blur: 0.5         JPEG: 0.5  |
| Model1        | 20-class Pro-GAN | Blur: N/A        JPEG: N/A   |
| Model2        | 20-class Pro-GAN | Blur: 0.5         JPEG: N/A  |
| Model3        | 20-class Pro-GAN | Blur: N/A        JPEG: 0.5   |
| Model4        | 20-class Pro-GAN | Blur: 0.5         JPEG: 0.5  |
| Model5        | 20-class Pro-GAN | Blur: 0.1         JPEG: 0.1  |

### Quick test

```bash
python test_demo.py --model ./trained_model/model1/baseline-cp-8.ckpt --image ./demo_images/real.png
```

