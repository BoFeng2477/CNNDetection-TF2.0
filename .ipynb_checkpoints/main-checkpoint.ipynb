{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uses only 1 class of the training dataset for demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training via command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with:\n",
      "Training set index: Img_index/train/1class.csv\n",
      "Validation set index: Img_index/val/progan_val.csv\n",
      "Epoch 1/8\n",
      "\n",
      "  1/562 [..............................] - ETA: 0s - loss: 0.8566 - accuracy: 0.3750\n",
      "  2/562 [..............................] - ETA: 1:45 - loss: 0.8281 - accuracy: 0.4062\n",
      "  3/562 [..............................] - ETA: 2:20 - loss: 0.7981 - accuracy: 0.4583\n",
      "  4/562 [..............................] - ETA: 2:37 - loss: 0.7651 - accuracy: 0.5000\n",
      "  5/562 [..............................] - ETA: 2:48 - loss: 0.7138 - accuracy: 0.5531\n",
      "  6/562 [..............................] - ETA: 2:54 - loss: 0.6802 - accuracy: 0.5911\n",
      "  7/562 [..............................] - ETA: 2:59 - loss: 0.6579 - accuracy: 0.6049\n",
      "  8/562 [..............................] - ETA: 3:02 - loss: 0.6396 - accuracy: 0.6094\n",
      "  9/562 [..............................] - ETA: 3:05 - loss: 0.6111 - accuracy: 0.6337\n",
      " 10/562 [..............................] - ETA: 3:07 - loss: 0.5866 - accuracy: 0.6516\n",
      " 11/562 [..............................] - ETA: 3:08 - loss: 0.5657 - accuracy: 0.6690\n",
      " 12/562 [..............................] - ETA: 3:09 - loss: 0.5585 - accuracy: 0.6797\n",
      " 13/562 [..............................] - ETA: 3:10 - loss: 0.5415 - accuracy: 0.6947\n",
      " 14/562 [..............................] - ETA: 3:11 - loss: 0.5328 - accuracy: 0.7009\n",
      " 15/562 [..............................] - ETA: 3:12 - loss: 0.5226 - accuracy: 0.7125\n",
      " 16/562 [..............................] - ETA: 3:12 - loss: 0.5132 - accuracy: 0.7178\n",
      " 17/562 [..............................] - ETA: 3:12 - loss: 0.4983 - accuracy: 0.7270\n",
      " 18/562 [..............................] - ETA: 3:13 - loss: 0.4896 - accuracy: 0.7361\n",
      " 19/562 [>.............................] - ETA: 3:13 - loss: 0.4795 - accuracy: 0.7442\n",
      " 20/562 [>.............................] - ETA: 3:13 - loss: 0.4695 - accuracy: 0.7500\n",
      " 21/562 [>.............................] - ETA: 3:13 - loss: 0.4582 - accuracy: 0.7574\n",
      " 22/562 [>.............................] - ETA: 3:13 - loss: 0.4479 - accuracy: 0.7649\n",
      " 23/562 [>.............................] - ETA: 3:13 - loss: 0.4406 - accuracy: 0.7690\n",
      " 24/562 [>.............................] - ETA: 3:13 - loss: 0.4321 - accuracy: 0.7728\n",
      " 25/562 [>.............................] - ETA: 3:13 - loss: 0.4258 - accuracy: 0.7775\n",
      " 26/562 [>.............................] - ETA: 3:13 - loss: 0.4200 - accuracy: 0.7812\n",
      " 27/562 [>.............................] - ETA: 3:13 - loss: 0.4123 - accuracy: 0.7859\n",
      " 28/562 [>.............................] - ETA: 3:13 - loss: 0.4114 - accuracy: 0.7896\n",
      " 29/562 [>.............................] - ETA: 3:13 - loss: 0.4030 - accuracy: 0.7963\n",
      " 30/562 [>.............................] - ETA: 3:13 - loss: 0.3983 - accuracy: 0.8005\n",
      " 31/562 [>.............................] - ETA: 3:13 - loss: 0.3912 - accuracy: 0.8059\n",
      " 32/562 [>.............................] - ETA: 3:12 - loss: 0.3838 - accuracy: 0.8105\n",
      " 33/562 [>.............................] - ETA: 3:12 - loss: 0.3759 - accuracy: 0.8149\n",
      " 34/562 [>.............................] - ETA: 3:12 - loss: 0.3670 - accuracy: 0.8199\n",
      " 35/562 [>.............................] - ETA: 3:12 - loss: 0.3606 - accuracy: 0.8232\n",
      " 36/562 [>.............................] - ETA: 3:12 - loss: 0.3545 - accuracy: 0.8260\n",
      " 37/562 [>.............................] - ETA: 3:12 - loss: 0.3497 - accuracy: 0.8269\n",
      " 38/562 [=>............................] - ETA: 3:11 - loss: 0.3455 - accuracy: 0.8298\n",
      " 39/562 [=>............................] - ETA: 3:11 - loss: 0.3391 - accuracy: 0.8341\n",
      " 40/562 [=>............................] - ETA: 3:11 - loss: 0.3321 - accuracy: 0.8375\n",
      " 41/562 [=>............................] - ETA: 3:11 - loss: 0.3259 - accuracy: 0.8396\n",
      " 42/562 [=>............................] - ETA: 3:10 - loss: 0.3240 - accuracy: 0.8423\n",
      " 43/562 [=>............................] - ETA: 3:10 - loss: 0.3188 - accuracy: 0.8452\n",
      " 44/562 [=>............................] - ETA: 3:10 - loss: 0.3133 - accuracy: 0.8480\n",
      " 45/562 [=>............................] - ETA: 3:10 - loss: 0.3080 - accuracy: 0.8510\n",
      " 46/562 [=>............................] - ETA: 3:09 - loss: 0.3026 - accuracy: 0.8533\n",
      " 47/562 [=>............................] - ETA: 3:09 - loss: 0.2971 - accuracy: 0.8561\n",
      " 48/562 [=>............................] - ETA: 3:09 - loss: 0.2929 - accuracy: 0.8574\n",
      " 49/562 [=>............................] - ETA: 3:08 - loss: 0.2872 - accuracy: 0.8603\n",
      " 50/562 [=>............................] - ETA: 3:08 - loss: 0.2842 - accuracy: 0.8622\n",
      " 51/562 [=>............................] - ETA: 3:08 - loss: 0.2800 - accuracy: 0.8640\n",
      " 52/562 [=>............................] - ETA: 3:08 - loss: 0.2767 - accuracy: 0.8660\n",
      " 53/562 [=>............................] - ETA: 3:07 - loss: 0.2747 - accuracy: 0.8667\n",
      " 54/562 [=>............................] - ETA: 3:07 - loss: 0.2701 - accuracy: 0.8692\n",
      " 55/562 [=>............................] - ETA: 3:07 - loss: 0.2662 - accuracy: 0.8710\n",
      " 56/562 [=>............................] - ETA: 3:06 - loss: 0.2627 - accuracy: 0.8730\n",
      " 57/562 [==>...........................] - ETA: 3:06 - loss: 0.2591 - accuracy: 0.8750\n",
      " 58/562 [==>...........................] - ETA: 3:06 - loss: 0.2566 - accuracy: 0.8769\n",
      " 59/562 [==>...........................] - ETA: 3:05 - loss: 0.2538 - accuracy: 0.8779\n",
      " 60/562 [==>...........................] - ETA: 3:05 - loss: 0.2517 - accuracy: 0.8792\n",
      " 61/562 [==>...........................] - ETA: 3:05 - loss: 0.2486 - accuracy: 0.8804\n",
      " 62/562 [==>...........................] - ETA: 3:04 - loss: 0.2457 - accuracy: 0.8821\n",
      " 63/562 [==>...........................] - ETA: 3:04 - loss: 0.2432 - accuracy: 0.8834\n",
      " 64/562 [==>...........................] - ETA: 3:04 - loss: 0.2405 - accuracy: 0.8848\n",
      " 65/562 [==>...........................] - ETA: 3:04 - loss: 0.2373 - accuracy: 0.8861\n",
      " 66/562 [==>...........................] - ETA: 3:03 - loss: 0.2355 - accuracy: 0.8871\n",
      " 67/562 [==>...........................] - ETA: 3:03 - loss: 0.2336 - accuracy: 0.8881\n",
      " 68/562 [==>...........................] - ETA: 3:03 - loss: 0.2308 - accuracy: 0.8897\n",
      " 69/562 [==>...........................] - ETA: 3:02 - loss: 0.2282 - accuracy: 0.8906\n",
      " 70/562 [==>...........................] - ETA: 3:02 - loss: 0.2258 - accuracy: 0.8917\n",
      " 71/562 [==>...........................] - ETA: 3:02 - loss: 0.2235 - accuracy: 0.8928\n",
      " 72/562 [==>...........................] - ETA: 3:01 - loss: 0.2211 - accuracy: 0.8939\n",
      " 73/562 [==>...........................] - ETA: 3:01 - loss: 0.2192 - accuracy: 0.8949\n",
      " 74/562 [==>...........................] - ETA: 3:01 - loss: 0.2176 - accuracy: 0.8961\n",
      " 75/562 [===>..........................] - ETA: 3:00 - loss: 0.2176 - accuracy: 0.8969\n",
      " 76/562 [===>..........................] - ETA: 3:00 - loss: 0.2161 - accuracy: 0.8974\n",
      " 77/562 [===>..........................] - ETA: 2:59 - loss: 0.2143 - accuracy: 0.8981\n",
      " 78/562 [===>..........................] - ETA: 2:59 - loss: 0.2124 - accuracy: 0.8992\n",
      " 79/562 [===>..........................] - ETA: 2:59 - loss: 0.2105 - accuracy: 0.9003\n",
      " 80/562 [===>..........................] - ETA: 2:58 - loss: 0.2083 - accuracy: 0.9014\n",
      " 81/562 [===>..........................] - ETA: 2:58 - loss: 0.2071 - accuracy: 0.9018\n",
      " 82/562 [===>..........................] - ETA: 2:58 - loss: 0.2068 - accuracy: 0.9024\n",
      " 83/562 [===>..........................] - ETA: 2:57 - loss: 0.2049 - accuracy: 0.9032\n",
      " 84/562 [===>..........................] - ETA: 2:57 - loss: 0.2029 - accuracy: 0.9044\n",
      " 85/562 [===>..........................] - ETA: 2:57 - loss: 0.2015 - accuracy: 0.9053\n",
      " 86/562 [===>..........................] - ETA: 2:56 - loss: 0.2007 - accuracy: 0.9059\n",
      " 87/562 [===>..........................] - ETA: 2:56 - loss: 0.1999 - accuracy: 0.9061\n",
      " 88/562 [===>..........................] - ETA: 2:56 - loss: 0.1981 - accuracy: 0.9070\n",
      " 89/562 [===>..........................] - ETA: 2:55 - loss: 0.1963 - accuracy: 0.9078\n",
      " 90/562 [===>..........................] - ETA: 2:55 - loss: 0.1945 - accuracy: 0.9089\n",
      " 91/562 [===>..........................] - ETA: 2:55 - loss: 0.1932 - accuracy: 0.9097\n",
      " 92/562 [===>..........................] - ETA: 2:54 - loss: 0.1919 - accuracy: 0.9103\n",
      " 93/562 [===>..........................] - ETA: 2:54 - loss: 0.1910 - accuracy: 0.9108\n",
      " 94/562 [====>.........................] - ETA: 2:54 - loss: 0.1896 - accuracy: 0.9114\n",
      " 95/562 [====>.........................] - ETA: 2:53 - loss: 0.1883 - accuracy: 0.9122\n",
      " 96/562 [====>.........................] - ETA: 2:53 - loss: 0.1867 - accuracy: 0.9131\n",
      " 97/562 [====>.........................] - ETA: 2:53 - loss: 0.1862 - accuracy: 0.9135\n",
      " 98/562 [====>.........................] - ETA: 2:52 - loss: 0.1856 - accuracy: 0.9134\n",
      " 99/562 [====>.........................] - ETA: 2:52 - loss: 0.1839 - accuracy: 0.9143\n",
      "100/562 [====>.........................] - ETA: 2:51 - loss: 0.1826 - accuracy: 0.9148\n",
      "101/562 [====>.........................] - ETA: 2:51 - loss: 0.1810 - accuracy: 0.9155\n",
      "102/562 [====>.........................] - ETA: 2:51 - loss: 0.1802 - accuracy: 0.9159\n",
      "103/562 [====>.........................] - ETA: 2:50 - loss: 0.1790 - accuracy: 0.9166\n",
      "104/562 [====>.........................] - ETA: 2:50 - loss: 0.1787 - accuracy: 0.9166\n",
      "105/562 [====>.........................] - ETA: 2:50 - loss: 0.1776 - accuracy: 0.9171\n",
      "106/562 [====>.........................] - ETA: 2:49 - loss: 0.1770 - accuracy: 0.9173\n",
      "107/562 [====>.........................] - ETA: 2:49 - loss: 0.1759 - accuracy: 0.9178\n",
      "108/562 [====>.........................] - ETA: 2:49 - loss: 0.1752 - accuracy: 0.9183\n",
      "109/562 [====>.........................] - ETA: 2:48 - loss: 0.1739 - accuracy: 0.9189\n",
      "110/562 [====>.........................] - ETA: 2:48 - loss: 0.1727 - accuracy: 0.9196\n",
      "111/562 [====>.........................] - ETA: 2:48 - loss: 0.1713 - accuracy: 0.9203\n",
      "112/562 [====>.........................] - ETA: 2:47 - loss: 0.1700 - accuracy: 0.9210\n",
      "113/562 [=====>........................] - ETA: 2:47 - loss: 0.1689 - accuracy: 0.9215\n",
      "114/562 [=====>........................] - ETA: 2:47 - loss: 0.1677 - accuracy: 0.9220\n",
      "115/562 [=====>........................] - ETA: 2:46 - loss: 0.1664 - accuracy: 0.9227\n",
      "116/562 [=====>........................] - ETA: 2:46 - loss: 0.1652 - accuracy: 0.9234\n",
      "117/562 [=====>........................] - ETA: 2:45 - loss: 0.1641 - accuracy: 0.9240\n",
      "118/562 [=====>........................] - ETA: 2:45 - loss: 0.1629 - accuracy: 0.9247\n",
      "119/562 [=====>........................] - ETA: 2:45 - loss: 0.1618 - accuracy: 0.9252\n",
      "120/562 [=====>........................] - ETA: 2:44 - loss: 0.1606 - accuracy: 0.9258\n",
      "121/562 [=====>........................] - ETA: 2:44 - loss: 0.1596 - accuracy: 0.9261\n",
      "122/562 [=====>........................] - ETA: 2:44 - loss: 0.1587 - accuracy: 0.9265\n",
      "123/562 [=====>........................] - ETA: 2:43 - loss: 0.1577 - accuracy: 0.9270\n",
      "124/562 [=====>........................] - ETA: 2:43 - loss: 0.1566 - accuracy: 0.9275\n",
      "125/562 [=====>........................] - ETA: 2:43 - loss: 0.1556 - accuracy: 0.9280\n",
      "126/562 [=====>........................] - ETA: 2:42 - loss: 0.1544 - accuracy: 0.9286\n",
      "127/562 [=====>........................] - ETA: 2:42 - loss: 0.1534 - accuracy: 0.9290\n",
      "128/562 [=====>........................] - ETA: 2:41 - loss: 0.1525 - accuracy: 0.9294\n",
      "129/562 [=====>........................] - ETA: 2:41 - loss: 0.1520 - accuracy: 0.9297\n",
      "130/562 [=====>........................] - ETA: 2:41 - loss: 0.1510 - accuracy: 0.9303\n",
      "131/562 [=====>........................] - ETA: 2:40 - loss: 0.1500 - accuracy: 0.9308\n",
      "132/562 [======>.......................] - ETA: 2:40 - loss: 0.1489 - accuracy: 0.9313\n",
      "133/562 [======>.......................] - ETA: 2:40 - loss: 0.1479 - accuracy: 0.9317\n",
      "134/562 [======>.......................] - ETA: 2:39 - loss: 0.1470 - accuracy: 0.9323\n",
      "135/562 [======>.......................] - ETA: 2:39 - loss: 0.1462 - accuracy: 0.9325\n",
      "136/562 [======>.......................] - ETA: 2:39 - loss: 0.1453 - accuracy: 0.9329\n",
      "137/562 [======>.......................] - ETA: 2:38 - loss: 0.1443 - accuracy: 0.9334\n",
      "138/562 [======>.......................] - ETA: 2:38 - loss: 0.1443 - accuracy: 0.9337\n",
      "139/562 [======>.......................] - ETA: 2:38 - loss: 0.1433 - accuracy: 0.9341\n",
      "140/562 [======>.......................] - ETA: 2:37 - loss: 0.1426 - accuracy: 0.9344\n",
      "141/562 [======>.......................] - ETA: 2:37 - loss: 0.1418 - accuracy: 0.9347\n",
      "142/562 [======>.......................] - ETA: 2:37 - loss: 0.1413 - accuracy: 0.9350\n",
      "143/562 [======>.......................] - ETA: 2:36 - loss: 0.1404 - accuracy: 0.9354\n",
      "144/562 [======>.......................] - ETA: 2:36 - loss: 0.1408 - accuracy: 0.9354\n",
      "145/562 [======>.......................] - ETA: 2:35 - loss: 0.1400 - accuracy: 0.9358\n",
      "146/562 [======>.......................] - ETA: 2:35 - loss: 0.1391 - accuracy: 0.9362\n",
      "147/562 [======>.......................] - ETA: 2:35 - loss: 0.1386 - accuracy: 0.9365\n",
      "148/562 [======>.......................] - ETA: 2:34 - loss: 0.1379 - accuracy: 0.9370\n",
      "149/562 [======>.......................] - ETA: 2:34 - loss: 0.1372 - accuracy: 0.9373\n",
      "150/562 [=======>......................] - ETA: 2:34 - loss: 0.1365 - accuracy: 0.9376\n",
      "151/562 [=======>......................] - ETA: 2:33 - loss: 0.1358 - accuracy: 0.9380\n",
      "152/562 [=======>......................] - ETA: 2:33 - loss: 0.1351 - accuracy: 0.9383\n",
      "153/562 [=======>......................] - ETA: 2:33 - loss: 0.1344 - accuracy: 0.9386\n",
      "154/562 [=======>......................] - ETA: 2:32 - loss: 0.1340 - accuracy: 0.9389\n",
      "155/562 [=======>......................] - ETA: 2:32 - loss: 0.1332 - accuracy: 0.9392\n",
      "156/562 [=======>......................] - ETA: 2:32 - loss: 0.1325 - accuracy: 0.9396\n",
      "157/562 [=======>......................] - ETA: 2:31 - loss: 0.1320 - accuracy: 0.9399\n",
      "158/562 [=======>......................] - ETA: 2:31 - loss: 0.1314 - accuracy: 0.9402\n",
      "159/562 [=======>......................] - ETA: 2:30 - loss: 0.1306 - accuracy: 0.9405\n",
      "160/562 [=======>......................] - ETA: 2:30 - loss: 0.1301 - accuracy: 0.9407\n",
      "161/562 [=======>......................] - ETA: 2:30 - loss: 0.1293 - accuracy: 0.9411\n",
      "162/562 [=======>......................] - ETA: 2:29 - loss: 0.1293 - accuracy: 0.9410\n",
      "163/562 [=======>......................] - ETA: 2:29 - loss: 0.1285 - accuracy: 0.9413\n",
      "164/562 [=======>......................] - ETA: 2:29 - loss: 0.1281 - accuracy: 0.9415\n",
      "165/562 [=======>......................] - ETA: 2:28 - loss: 0.1276 - accuracy: 0.9418\n",
      "166/562 [=======>......................] - ETA: 2:28 - loss: 0.1269 - accuracy: 0.9421\n",
      "167/562 [=======>......................] - ETA: 2:28 - loss: 0.1263 - accuracy: 0.9424\n",
      "168/562 [=======>......................] - ETA: 2:27 - loss: 0.1260 - accuracy: 0.9426\n",
      "169/562 [========>.....................] - ETA: 2:27 - loss: 0.1255 - accuracy: 0.9429\n",
      "170/562 [========>.....................] - ETA: 2:26 - loss: 0.1250 - accuracy: 0.9431\n",
      "171/562 [========>.....................] - ETA: 2:26 - loss: 0.1243 - accuracy: 0.9434\n",
      "172/562 [========>.....................] - ETA: 2:26 - loss: 0.1236 - accuracy: 0.9438\n",
      "173/562 [========>.....................] - ETA: 2:25 - loss: 0.1231 - accuracy: 0.9440\n",
      "174/562 [========>.....................] - ETA: 2:25 - loss: 0.1227 - accuracy: 0.9442\n",
      "175/562 [========>.....................] - ETA: 2:25 - loss: 0.1221 - accuracy: 0.9446\n",
      "176/562 [========>.....................] - ETA: 2:24 - loss: 0.1218 - accuracy: 0.9446\n",
      "177/562 [========>.....................] - ETA: 2:24 - loss: 0.1213 - accuracy: 0.9449\n",
      "178/562 [========>.....................] - ETA: 2:24 - loss: 0.1207 - accuracy: 0.9452\n",
      "179/562 [========>.....................] - ETA: 2:23 - loss: 0.1200 - accuracy: 0.9455\n",
      "180/562 [========>.....................] - ETA: 2:23 - loss: 0.1194 - accuracy: 0.9458\n",
      "181/562 [========>.....................] - ETA: 2:22 - loss: 0.1189 - accuracy: 0.9460\n",
      "182/562 [========>.....................] - ETA: 2:22 - loss: 0.1187 - accuracy: 0.9461\n",
      "183/562 [========>.....................] - ETA: 2:22 - loss: 0.1184 - accuracy: 0.9461\n",
      "184/562 [========>.....................] - ETA: 2:21 - loss: 0.1179 - accuracy: 0.9464\n",
      "185/562 [========>.....................] - ETA: 2:21 - loss: 0.1175 - accuracy: 0.9466\n",
      "186/562 [========>.....................] - ETA: 2:21 - loss: 0.1170 - accuracy: 0.9468\n",
      "187/562 [========>.....................] - ETA: 2:20 - loss: 0.1164 - accuracy: 0.9471\n",
      "188/562 [=========>....................] - ETA: 2:20 - loss: 0.1161 - accuracy: 0.9473\n",
      "189/562 [=========>....................] - ETA: 2:20 - loss: 0.1155 - accuracy: 0.9476\n",
      "190/562 [=========>....................] - ETA: 2:19 - loss: 0.1153 - accuracy: 0.9476\n",
      "191/562 [=========>....................] - ETA: 2:19 - loss: 0.1148 - accuracy: 0.9479\n",
      "192/562 [=========>....................] - ETA: 2:18 - loss: 0.1145 - accuracy: 0.9481\n",
      "193/562 [=========>....................] - ETA: 2:18 - loss: 0.1139 - accuracy: 0.9483\n",
      "194/562 [=========>....................] - ETA: 2:18 - loss: 0.1134 - accuracy: 0.9485\n",
      "195/562 [=========>....................] - ETA: 2:17 - loss: 0.1130 - accuracy: 0.9487\n",
      "196/562 [=========>....................] - ETA: 2:17 - loss: 0.1125 - accuracy: 0.9490\n",
      "197/562 [=========>....................] - ETA: 2:17 - loss: 0.1120 - accuracy: 0.9492\n",
      "198/562 [=========>....................] - ETA: 2:16 - loss: 0.1115 - accuracy: 0.9494\n",
      "199/562 [=========>....................] - ETA: 2:16 - loss: 0.1109 - accuracy: 0.9497\n",
      "200/562 [=========>....................] - ETA: 2:16 - loss: 0.1105 - accuracy: 0.9499\n",
      "201/562 [=========>....................] - ETA: 2:15 - loss: 0.1101 - accuracy: 0.9501\n",
      "202/562 [=========>....................] - ETA: 2:15 - loss: 0.1096 - accuracy: 0.9503\n",
      "203/562 [=========>....................] - ETA: 2:14 - loss: 0.1091 - accuracy: 0.9506\n",
      "204/562 [=========>....................] - ETA: 2:14 - loss: 0.1086 - accuracy: 0.9508\n",
      "205/562 [=========>....................] - ETA: 2:14 - loss: 0.1082 - accuracy: 0.9511\n",
      "206/562 [=========>....................] - ETA: 2:13 - loss: 0.1077 - accuracy: 0.9512\n",
      "207/562 [==========>...................] - ETA: 2:13 - loss: 0.1075 - accuracy: 0.9513\n",
      "208/562 [==========>...................] - ETA: 2:13 - loss: 0.1071 - accuracy: 0.9515\n",
      "209/562 [==========>...................] - ETA: 2:12 - loss: 0.1066 - accuracy: 0.9517\n",
      "210/562 [==========>...................] - ETA: 2:12 - loss: 0.1063 - accuracy: 0.9519\n",
      "211/562 [==========>...................] - ETA: 2:11 - loss: 0.1060 - accuracy: 0.9521\n",
      "212/562 [==========>...................] - ETA: 2:11 - loss: 0.1055 - accuracy: 0.9523\n",
      "213/562 [==========>...................] - ETA: 2:11 - loss: 0.1051 - accuracy: 0.9525\n",
      "214/562 [==========>...................] - ETA: 2:10 - loss: 0.1047 - accuracy: 0.9527\n",
      "215/562 [==========>...................] - ETA: 2:10 - loss: 0.1043 - accuracy: 0.9528\n",
      "216/562 [==========>...................] - ETA: 2:10 - loss: 0.1040 - accuracy: 0.9528\n",
      "217/562 [==========>...................] - ETA: 2:09 - loss: 0.1037 - accuracy: 0.9530\n",
      "218/562 [==========>...................] - ETA: 2:09 - loss: 0.1037 - accuracy: 0.9531\n",
      "219/562 [==========>...................] - ETA: 2:09 - loss: 0.1036 - accuracy: 0.9533\n",
      "220/562 [==========>...................] - ETA: 2:08 - loss: 0.1032 - accuracy: 0.9535\n",
      "221/562 [==========>...................] - ETA: 2:08 - loss: 0.1032 - accuracy: 0.9535\n",
      "222/562 [==========>...................] - ETA: 2:07 - loss: 0.1028 - accuracy: 0.9536\n",
      "223/562 [==========>...................] - ETA: 2:07 - loss: 0.1026 - accuracy: 0.9536\n",
      "224/562 [==========>...................] - ETA: 2:07 - loss: 0.1023 - accuracy: 0.9538\n",
      "225/562 [===========>..................] - ETA: 2:06 - loss: 0.1021 - accuracy: 0.9540\n",
      "226/562 [===========>..................] - ETA: 2:06 - loss: 0.1018 - accuracy: 0.9541\n",
      "227/562 [===========>..................] - ETA: 2:06 - loss: 0.1017 - accuracy: 0.9542\n",
      "228/562 [===========>..................] - ETA: 2:05 - loss: 0.1014 - accuracy: 0.9544\n",
      "229/562 [===========>..................] - ETA: 2:05 - loss: 0.1011 - accuracy: 0.9545\n",
      "230/562 [===========>..................] - ETA: 2:04 - loss: 0.1007 - accuracy: 0.9547\n",
      "231/562 [===========>..................] - ETA: 2:04 - loss: 0.1003 - accuracy: 0.9549\n",
      "232/562 [===========>..................] - ETA: 2:04 - loss: 0.1001 - accuracy: 0.9549\n",
      "233/562 [===========>..................] - ETA: 2:03 - loss: 0.0997 - accuracy: 0.9551\n",
      "234/562 [===========>..................] - ETA: 2:03 - loss: 0.0994 - accuracy: 0.9553\n",
      "235/562 [===========>..................] - ETA: 2:03 - loss: 0.0989 - accuracy: 0.9555\n",
      "236/562 [===========>..................] - ETA: 2:02 - loss: 0.0985 - accuracy: 0.9557\n",
      "237/562 [===========>..................] - ETA: 2:02 - loss: 0.0982 - accuracy: 0.9559\n",
      "238/562 [===========>..................] - ETA: 2:01 - loss: 0.0978 - accuracy: 0.9559\n",
      "239/562 [===========>..................] - ETA: 2:01 - loss: 0.0975 - accuracy: 0.9561\n",
      "240/562 [===========>..................] - ETA: 2:01 - loss: 0.0971 - accuracy: 0.9563\n",
      "241/562 [===========>..................] - ETA: 2:00 - loss: 0.0970 - accuracy: 0.9564\n",
      "242/562 [===========>..................] - ETA: 2:00 - loss: 0.0968 - accuracy: 0.9565\n",
      "243/562 [===========>..................] - ETA: 2:00 - loss: 0.0964 - accuracy: 0.9567\n",
      "244/562 [============>.................] - ETA: 1:59 - loss: 0.0961 - accuracy: 0.9569\n",
      "245/562 [============>.................] - ETA: 1:59 - loss: 0.0957 - accuracy: 0.9571\n",
      "246/562 [============>.................] - ETA: 1:58 - loss: 0.0954 - accuracy: 0.9573\n",
      "247/562 [============>.................] - ETA: 1:58 - loss: 0.0951 - accuracy: 0.9574\n",
      "248/562 [============>.................] - ETA: 1:58 - loss: 0.0949 - accuracy: 0.9575\n",
      "249/562 [============>.................] - ETA: 1:57 - loss: 0.0946 - accuracy: 0.9577\n",
      "250/562 [============>.................] - ETA: 1:57 - loss: 0.0944 - accuracy: 0.9579\n",
      "251/562 [============>.................] - ETA: 1:57 - loss: 0.0941 - accuracy: 0.9580\n",
      "252/562 [============>.................] - ETA: 1:56 - loss: 0.0939 - accuracy: 0.9581\n",
      "253/562 [============>.................] - ETA: 1:56 - loss: 0.0937 - accuracy: 0.9583\n",
      "254/562 [============>.................] - ETA: 1:56 - loss: 0.0936 - accuracy: 0.9584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-18 12:19:46.375480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\n",
      "2020-12-18 12:19:47.930687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\n",
      "2020-12-18 12:19:47.949252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2020-12-18 12:19:47.949270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\n",
      "2020-12-18 12:19:47.954099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\n",
      "2020-12-18 12:19:47.956555: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\n",
      "2020-12-18 12:19:47.957786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\n",
      "2020-12-18 12:19:47.960950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\n",
      "2020-12-18 12:19:47.963332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\n",
      "2020-12-18 12:19:47.974599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\n",
      "2020-12-18 12:19:47.974652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2020-12-18 12:19:47.974815: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\n",
      "2020-12-18 12:19:47.980596: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17d53cf6ca0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-18 12:19:47.980607: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-12-18 12:19:47.980697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 2070 SUPER computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 40 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2020-12-18 12:19:47.980708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\n",
      "2020-12-18 12:19:47.980714: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\n",
      "2020-12-18 12:19:47.980718: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\n",
      "2020-12-18 12:19:47.980723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\n",
      "2020-12-18 12:19:47.980727: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\n",
      "2020-12-18 12:19:47.980732: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\n",
      "2020-12-18 12:19:47.980736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\n",
      "2020-12-18 12:19:47.980756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\n",
      "2020-12-18 12:19:48.366727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-12-18 12:19:48.366742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 \n",
      "2020-12-18 12:19:48.366746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N \n",
      "2020-12-18 12:19:48.366838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6620 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2020-12-18 12:19:48.368574: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17d6b5223c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-12-18 12:19:48.368583: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5\n",
      "2020-12-18 12:19:54.312177: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\n",
      "2020-12-18 12:19:54.590197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\n",
      "2020-12-18 12:19:55.255587: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2020-12-18 12:19:55.922317: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-12-18 12:19:55.922343: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-12-18 12:19:55.938498: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-12-18 12:19:55.938523: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-12-18 12:19:55.968689: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-12-18 12:19:55.968712: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-12-18 12:19:56.003685: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-12-18 12:19:56.003712: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-12-18 12:19:56.019734: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-12-18 12:19:56.019757: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2020-12-18 12:21:33.787214: E tensorflow/stream_executor/cuda/cuda_driver.cc:939] could not synchronize on CUDA context: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered :: 0x00007FFC76B78E85\ttensorflow::CurrentStackTrace\n",
      "0x00007FFC768AA4BE\ttensorflow::DeviceProperties::l2_cache_size\n",
      "0x00007FFC768B0BEE\tstream_executor::StreamExecutor::EnablePeerAccessTo\n",
      "0x00007FFC6369BF38\ttensorflow::StepStats::internal_default_instance\n",
      "0x00007FFC636AD064\tgoogle::protobuf::RepeatedPtrField<tensorflow::InterconnectLink>::Add\n",
      "0x00007FFC633E7712\tstd::vector<tensorflow::DtypeAndPartialTensorShape,std::allocator<tensorflow::DtypeAndPartialTensorShape> >::operator=\n",
      "0x00007FFC5E1CA4D1\ttensorflow::MemoryLogRawDeallocation::deferred\n",
      "0x00007FFC5E1D4A01\tTFE_TensorHandleResolve\n",
      "0x00007FFC5DF3D6A3\tTFE_Py_TensorShapeSlice\n",
      "0x00007FFC5DF3ADDA\tstd::vector<tensorflow::monitoring::Point::Label,std::allocator<tensorflow::monitoring::Point::Label> >::reserve\n",
      "0x00007FFCBF89EA27\tPyMethodDef_RawFastCallKeywords\n",
      "0x00007FFCBF89F0FC\tPyMethodDef_RawFastCallKeywords\n",
      "0x00007FFCBF89F8F3\tPyEval_EvalFrameDefault\n",
      "0x00007FFCBF89F25B\tPyMethodDef_RawFastCallKeywords\n",
      "0x00007FFCBF89F8F3\tPyEval_EvalFrameDefault\n",
      "0x00007FFCBF89F25B\tPyMethodDef_RawFastCallKeywords\n",
      "0x00007FFCBF89F8F3\tPyEval_EvalFrameDefault\n",
      "0x00007FFCBF888EB6\tPyEval_EvalCodeWithName\n",
      "0x00007FFCBF888B3A\tPyFunction_FastCallDict\n",
      "0x00007FFCBF8AED9D\tPySlice_New\n",
      "0x00007FFCBF8A0664\tPyEval_EvalFrameDefault\n",
      "0x00007FFCBF888EB6\tPyEval_EvalCodeWithName\n",
      "0x00007FFCBF89F387\tPyMethodDef_RawFastCallKeywords\n",
      "0x00007FFCBF89F99F\tPyEval_EvalFrameDefault\n",
      "0x00007FFCBF888EB6\tPyEval_EvalCodeWithName\n",
      "0x00007FFCBF89F387\tPyMethodDef_RawFastCallKeywords\n",
      "0x00007FFCBF89FDA2\tPyEval_EvalFrameDefault\n",
      "0x00007FFCBF89F25B\tPyMethodDef_RawFastCallKeywords\n",
      "0x00007FFCBF89FDA2\tPyEval_EvalFrameDefault\n",
      "0x00007FFCBF89F25B\tPyMethodDef_RawFastCallKeywords\n",
      "0x00007FFCBF89F8F3\tPyEval_EvalFrameDefault\n",
      "0x00007FFCBF888EB6\tPyEval_EvalCodeWithName\n",
      "0x00007FFCBF89F387\tPyMethodDef_RawFastCallKeywords\n",
      "0x00007FFCBF89F8F3\tPyEval_EvalFrameDefault\n",
      "0x00007FFCBF888EB6\tPyEval_EvalCodeWithName\n",
      "0x00007FFCBF888B3A\tPyFunction_FastCallDict\n",
      "0x00007FFCBF8AED9D\tPySlice_New\n",
      "0x00007FFCBF8A0664\tPyEval_EvalFrameDefault\n",
      "0x00007FFCBF888EB6\tPyEval_EvalCodeWithName\n",
      "0x00007FFCBF89F387\tPyMethodDef_RawFastCallKeywords\n",
      "0x00007FFCBF8A04E9\tPyEval_EvalFrameDefault\n",
      "0x00007FFCBF888EB6\tPyEval_EvalCodeWithName\n",
      "0x00007FFCBF89F387\tPyMethodDef_RawFastCallKeywords\n",
      "0x00007FFCBF8A04E9\tPyEval_EvalFrameDefault\n",
      "0x00007FFCBF888EB6\tPyEval_EvalCodeWithName\n",
      "0x00007FFCBF8A4A93\tPyEval_EvalCodeEx\n",
      "0x00007FFCBF8A49F1\tPyEval_EvalCode\n",
      "0x00007FFCBF8A499B\tPyArena_Free\n",
      "0x00007FFCBFA0600D\tPyRun_FileExFlags\n",
      "0x00007FFCBFA06834\tPyRun_SimpleFileExFlags\n",
      "0x00007FFCBFA05EDB\tPyRun_AnyFileExFlags\n",
      "0x00007FFCBF9518BB\tPy_UnixMain\n",
      "0x00007FFCBF951963\tPy_UnixMain\n",
      "0x00007FFCBF8E7D10\tPyErr_NoMemory\n",
      "0x00007FFCBF8613A5\tPy_Main\n",
      "0x00007FFCBF861052\tPy_Main\n",
      "0x00007FF6EF781268\t(unknown)\n",
      "0x00007FFD46757034\tBaseThreadInitThunk\n",
      "0x00007FFD4865D0D1\tRtlUserThreadStart\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train_script.py\", line 21, in <module>\n",
      "    start_epoch = args.start_epoch, batch_size = args.batch_size, epoch = args.epoch, seed = 8)\n",
      "  File \"C:\\Users\\Tim\\Downloads\\CNNDetection-TF2.0\\trainer.py\", line 32, in train\n",
      "    steps_per_epoch = steps, callbacks = [cp_callback], initial_epoch= start_epoch)\n",
      "  File \"C:\\Users\\Tim\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 66, in _method_wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\Tim\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 855, in fit\n",
      "    callbacks.on_train_batch_end(step, logs)\n",
      "  File \"C:\\Users\\Tim\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 389, in on_train_batch_end\n",
      "    logs = self._process_logs(logs)\n",
      "  File \"C:\\Users\\Tim\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 265, in _process_logs\n",
      "    return tf_utils.to_numpy_or_python_type(logs)\n",
      "  File \"C:\\Users\\Tim\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\", line 523, in to_numpy_or_python_type\n",
      "    return nest.map_structure(_to_single_numpy_or_python_type, tensors)\n",
      "  File \"C:\\Users\\Tim\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 617, in map_structure\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"C:\\Users\\Tim\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\", line 617, in <listcomp>\n",
      "    structure[0], [func(*x) for x in entries],\n",
      "  File \"C:\\Users\\Tim\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\", line 519, in _to_single_numpy_or_python_type\n",
      "    x = t.numpy()\n",
      "  File \"C:\\Users\\Tim\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 961, in numpy\n",
      "    maybe_arr = self._numpy()  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\Tim\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 929, in _numpy\n",
      "    six.raise_from(core._status_to_exception(e.code, e.message), None)\n",
      "  File \"<string>\", line 3, in raise_from\n",
      "tensorflow.python.framework.errors_impl.InternalError: GPU sync failed\n",
      "2020-12-18 12:21:33.844984: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.\n",
      "\t [[{{node PyFunc}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python train_script.py --train_dir ../Copy_of_progan_train/train/ --val_dir ../progan_val/ --batch_size 64 --train_index Img_index/train/1class.csv --val_index Img_index/val/progan_val.csv --epoch 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from trainer import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with:\n",
      "Training set index: Img_index/train/1class.csv\n",
      "Validation set index: Img_index/val/progan_val.csv\n",
      "Epoch 1/8\n",
      " 46/562 [=>............................] - ETA: 3:10 - loss: 0.2975 - accuracy: 0.8543"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5ba758b27fd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m      \u001b[0mtrain_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Img_index/train/1class.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m      \u001b[0mval_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Img_index/val/progan_val.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m      checkpoint = None, start_epoch = 0, batch_size = 64, epoch = 8)\n\u001b[0m",
      "\u001b[1;32m~\\Downloads\\CNNDetection-TF2.0\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_dir, val_dir, train_idx, val_idx, checkpoint, save_path, batch_size, epoch, start_epoch, seed)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \tmodel.fit(x = train_gen, validation_data =val_gen, epochs=epoch, shuffle = True,\n\u001b[1;32m---> 32\u001b[1;33m \t steps_per_epoch = steps, callbacks = [cp_callback], initial_epoch= start_epoch)\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    387\u001b[0m     \"\"\"\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[1;34m(self, logs)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 617\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    517\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    959\u001b[0m     \"\"\"\n\u001b[0;32m    960\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\envTF22\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    925\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_dir = '../Copy_of_progan_train/train/', \n",
    "     val_dir = '../progan_val/', \n",
    "     train_idx = 'Img_index/train/1class.csv', \n",
    "     val_idx = 'Img_index/val/progan_val.csv', \n",
    "     checkpoint = None, start_epoch = 0, batch_size = 64, epoch = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, precision_recall_curve, accuracy_score\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from Data.DataPipe import TestDataGenerator\n",
    "from Network.Det_RN50 import Det_RN50\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the path to models you want to test in this list\n",
    "models = [ \"./train_model/model5/model5-cp-8.ckpt\" ] \n",
    "\n",
    "# Put the names of test sets you want to test your model on in this list\n",
    "test_set = ['biggan','crn', \"cyclegan\", \"deepfake\", \"gaugan\", \"imle\", \"progan\", \"san\", \"seeingdark\", \n",
    "            \"stargan\", \"stylegan\", \"stylegan2\", \"whichfaceisreal\"] \n",
    "\n",
    "for ckpt in models[:]:\n",
    "    model = Det_RN50()\n",
    "    model.load_weights(ckpt)\n",
    "    for test_name in test_set[:]:\n",
    "        print('\\n\\nModel Loaded:{}'.format(ckpt))\n",
    "        print('\\nTesting on:{}\\n'.format(test_name))\n",
    "        img_idx = \"Img_index/test/\" + test_name + \"_test.csv\"\n",
    "        root = \"../CNN_synth_testset/\" + test_name + \"/\"\n",
    "        img_idx = pd.read_csv(img_idx)\n",
    "        ANS = pd.DataFrame(columns=['file','label'])\n",
    "        len_size = len(img_idx)\n",
    "        with tqdm(total=len_size) as pbar:\n",
    "            for i,row in img_idx.iterrows():\n",
    "                img = cv2.imread(root+row['file'])\n",
    "                img = img/255.0\n",
    "                h,w,c = img.shape\n",
    "                img = img.reshape(1,h,w,3)\n",
    "                pred = model.predict(img)[0][0]\n",
    "                pred = tf.sigmoid(pred).numpy()\n",
    "                ANS = ANS.append({'file':row['file'],'label':pred},ignore_index=True)\n",
    "                pbar.update(1)\n",
    "        ANS.to_csv('test_results/'+ckpt.split('/')[2]+'/'+test_name+'.csv',columns=['file','label'],index=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [\"progan\",\"stylegan\",'biggan', \"cyclegan\",\"stargan\", \"gaugan\",'crn', \"imle\", \"seeingdark\",\"san\",  \"deepfake\", \n",
    "             \"stylegan2\",'whichfaceisreal']\n",
    "models = ['model-2c','model-8c','model1','model2','model3','model4','model5']\n",
    "\n",
    "result_table = pd.DataFrame(columns=[\"progan\",\"stylegan\",'biggan', \"cyclegan\",\"stargan\", \"gaugan\",'crn', \"imle\", \"seeingdark\",\"san\",  \"deepfake\", \n",
    "             \"stylegan2\",'whichfaceisreal'])\n",
    "\n",
    "for model in models[:]:\n",
    "    result = {\"progan\":0,\"stylegan\":0,'biggan':0, \"cyclegan\":0,\"stargan\":0, \"gaugan\":0,'crn':0, \"imle\":0, \"seeingdark\":0,\"san\":0,\"deepfake\":0, \n",
    "             \"stylegan2\":0,'whichfaceisreal':0}\n",
    "    for dataset in test_set[:]:      \n",
    "        model_name = model\n",
    "        dataset = dataset\n",
    "        gt_path = 'Img_index/test/' + dataset + '_test.csv'\n",
    "        pred_path = 'test_results/'+model_name+'/' + dataset + '.csv'\n",
    "\n",
    "        y_true = np.array(pd.read_csv(gt_path)['label'])\n",
    "        y_pred = np.array(pd.read_csv(pred_path)['label'])\n",
    "\n",
    "        r_acc = accuracy_score(y_true[y_true==0], y_pred[y_true==0] > 0.5)\n",
    "        f_acc = accuracy_score(y_true[y_true==1], y_pred[y_true==1] > 0.5)\n",
    "        acc = accuracy_score(y_true, y_pred > 0.5)\n",
    "        ap = average_precision_score(y_true, y_pred)\n",
    "        result[dataset] = np.round(100*ap,1)\n",
    "    \n",
    "    series = pd.Series(result,name=model)\n",
    "    result_table = result_table.append(series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>progan</th>\n",
       "      <th>stylegan</th>\n",
       "      <th>biggan</th>\n",
       "      <th>cyclegan</th>\n",
       "      <th>stargan</th>\n",
       "      <th>gaugan</th>\n",
       "      <th>crn</th>\n",
       "      <th>imle</th>\n",
       "      <th>seeingdark</th>\n",
       "      <th>san</th>\n",
       "      <th>deepfake</th>\n",
       "      <th>stylegan2</th>\n",
       "      <th>whichfaceisreal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model-2c</th>\n",
       "      <td>97.6</td>\n",
       "      <td>82.3</td>\n",
       "      <td>66.4</td>\n",
       "      <td>82.8</td>\n",
       "      <td>85.5</td>\n",
       "      <td>88.1</td>\n",
       "      <td>96.2</td>\n",
       "      <td>97.9</td>\n",
       "      <td>79.2</td>\n",
       "      <td>58.1</td>\n",
       "      <td>61.7</td>\n",
       "      <td>81.1</td>\n",
       "      <td>99.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model-8c</th>\n",
       "      <td>100.0</td>\n",
       "      <td>95.2</td>\n",
       "      <td>68.3</td>\n",
       "      <td>87.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>63.4</td>\n",
       "      <td>98.4</td>\n",
       "      <td>95.3</td>\n",
       "      <td>97.5</td>\n",
       "      <td>87.1</td>\n",
       "      <td>94.8</td>\n",
       "      <td>95.4</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>96.6</td>\n",
       "      <td>72.1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>59.3</td>\n",
       "      <td>97.8</td>\n",
       "      <td>94.1</td>\n",
       "      <td>98.9</td>\n",
       "      <td>91.1</td>\n",
       "      <td>96.4</td>\n",
       "      <td>99.8</td>\n",
       "      <td>97.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>96.5</td>\n",
       "      <td>76.7</td>\n",
       "      <td>84.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>65.1</td>\n",
       "      <td>92.6</td>\n",
       "      <td>93.8</td>\n",
       "      <td>99.6</td>\n",
       "      <td>49.1</td>\n",
       "      <td>67.3</td>\n",
       "      <td>99.4</td>\n",
       "      <td>98.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>96.2</td>\n",
       "      <td>74.7</td>\n",
       "      <td>86.1</td>\n",
       "      <td>95.9</td>\n",
       "      <td>90.3</td>\n",
       "      <td>99.4</td>\n",
       "      <td>99.6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>69.3</td>\n",
       "      <td>88.5</td>\n",
       "      <td>94.6</td>\n",
       "      <td>95.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>97.7</td>\n",
       "      <td>78.1</td>\n",
       "      <td>91.9</td>\n",
       "      <td>98.2</td>\n",
       "      <td>92.4</td>\n",
       "      <td>96.7</td>\n",
       "      <td>98.1</td>\n",
       "      <td>99.2</td>\n",
       "      <td>56.2</td>\n",
       "      <td>65.9</td>\n",
       "      <td>98.5</td>\n",
       "      <td>99.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model5</th>\n",
       "      <td>99.6</td>\n",
       "      <td>93.6</td>\n",
       "      <td>72.1</td>\n",
       "      <td>81.7</td>\n",
       "      <td>99.2</td>\n",
       "      <td>73.1</td>\n",
       "      <td>87.7</td>\n",
       "      <td>81.5</td>\n",
       "      <td>98.8</td>\n",
       "      <td>54.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>97.4</td>\n",
       "      <td>97.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          progan  stylegan  biggan  cyclegan  stargan  gaugan   crn  imle  \\\n",
       "model-2c    97.6      82.3    66.4      82.8     85.5    88.1  96.2  97.9   \n",
       "model-8c   100.0      95.2    68.3      87.1    100.0    63.4  98.4  95.3   \n",
       "model1     100.0      96.6    72.1      76.0    100.0    59.3  97.8  94.1   \n",
       "model2     100.0      96.5    76.7      84.4    100.0    65.1  92.6  93.8   \n",
       "model3     100.0      96.2    74.7      86.1     95.9    90.3  99.4  99.6   \n",
       "model4     100.0      97.7    78.1      91.9     98.2    92.4  96.7  98.1   \n",
       "model5      99.6      93.6    72.1      81.7     99.2    73.1  87.7  81.5   \n",
       "\n",
       "          seeingdark   san  deepfake  stylegan2  whichfaceisreal  \n",
       "model-2c        79.2  58.1      61.7       81.1             99.1  \n",
       "model-8c        97.5  87.1      94.8       95.4             94.0  \n",
       "model1          98.9  91.1      96.4       99.8             97.5  \n",
       "model2          99.6  49.1      67.3       99.4             98.9  \n",
       "model3          85.0  69.3      88.5       94.6             95.3  \n",
       "model4          99.2  56.2      65.9       98.5             99.7  \n",
       "model5          98.8  54.5      68.0       97.4             97.5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
